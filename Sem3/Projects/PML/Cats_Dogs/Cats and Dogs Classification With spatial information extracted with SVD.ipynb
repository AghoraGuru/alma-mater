{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "\n",
    "class KNeighborsClassifier():\n",
    "    \n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.neighbors = n_neighbors\n",
    "        \n",
    "    def fit():\n",
    "        pass\n",
    "    \n",
    "    def predict():\n",
    "        pass\n",
    "    \n",
    "    def euclidian_dist(self, point_1, point_2):\n",
    "        dist = 0.0\n",
    "        for i in range(len(point_1) - 1):\n",
    "            dist += pow(point_1[i] - point_2[i], 2)\n",
    "        return np.sqrt(dist)\n",
    "    \n",
    "    def calc_distances(self, data, new_point):\n",
    "        distances = []\n",
    "        neighbors = []\n",
    "        for i in data:\n",
    "            distances.append((i, self.euclidian_dist(new_point, i)))\n",
    "        distances.sort(key=operator.itemgetter(1))\n",
    "        for i in range(self.neighbors):\n",
    "            neighbors.append(distances[i][0])\n",
    "        return neighbors\n",
    "    \n",
    "    def find_majority(self, neighbors, train_X, train_y):\n",
    "        iter_y = []\n",
    "        for i in neighbors:\n",
    "            iter_y.append(train_y[np.where(train_X == i)[0][0]])\n",
    "        return max(iter_y)\n",
    "    \n",
    "    def fit(self, train_X, train_y):\n",
    "        set_of_classes = set(train_y)\n",
    "        self.classes = 0;\n",
    "        for i in set_of_classes:\n",
    "            self.classes += 1\n",
    "        self.X = train_X\n",
    "        self.y = train_y\n",
    "        self.data_len = len(train_X)\n",
    "        \n",
    "    def predict(self, test_y):\n",
    "        y_pred = []\n",
    "        neighbors = []\n",
    "        for i in test_y:\n",
    "            neighbors = self.calc_distances(self.X, i)\n",
    "            y_pred.append(self.find_majority(neighbors, self.X, self.y))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kmeans():\n",
    "    \n",
    "    def __init__(self, n_clusters=5):\n",
    "        self.clusters = n_clusters\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "        self.data_len = len(X)\n",
    "        self.centroids = []\n",
    "        for i in range(self.clusters):\n",
    "            self.centroids.append(X[i])\n",
    "        self.centroids = np.array(self.centroids)\n",
    "        self.clusters = np.zeros(self.data_len)\n",
    "\n",
    "    def euclidian_dist(self, point_1, point_2):\n",
    "        dist = 0.0\n",
    "        for i in range(len(point_1)):\n",
    "            dist += pow(point_1[i] - point_2[i], 2)\n",
    "        return np.sqrt(dist)\n",
    "\n",
    "    def calc_distances(self, data, new_point):\n",
    "        distances = []\n",
    "        for i in data:\n",
    "            distances.append(self.euclidian_dist(new_point, i))\n",
    "        return distances\n",
    "\n",
    "    def find_nearest_centroid(self, new_point):\n",
    "        distances = self.calc_distances(self.centroids, new_point)\n",
    "        return np.argmin(distances)\n",
    "\n",
    "    def update_centroids(self):\n",
    "        for i in range(self.clusters):\n",
    "            points = [self.X[j] for j in range(len(self.X)) if self.clusters[j] == i]\n",
    "            self.centroids[i] = np.mean(points, axis=0)\n",
    "            \n",
    "    def predict(self, test_X):\n",
    "        y_pred = []\n",
    "        for i in test_X:\n",
    "            y_pred.append(self.find_nearest_centroid(i))\n",
    "        return y_pred\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training cat images: 25\n",
      "Total training dog images: 25\n",
      "Total test cat images: 50\n",
      "Total test dog images: 50\n"
     ]
    }
   ],
   "source": [
    "#importing the data\n",
    "data_dir = '/home/kalyan/DataSets/DogsandCats/random_images'\n",
    "train_dir = os.path.join(data_dir, 'training_set/training_set/')\n",
    "test_dir = os.path.join(data_dir, 'test_set/test_set')\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "\n",
    "\n",
    "#checking the number of images in each folder\n",
    "print('Total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "print('Total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "print('Total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "print('Total test dog images:', len(os.listdir(test_dogs_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking svd of the images and to truncatate first 10 features of the images as it is most contributing to the images\n",
    "'''\n",
    "Input : An image and number of features to be truncated\n",
    "Output : Truncated US matrix\n",
    "'''\n",
    "def svd_truncate(img, n):\n",
    "    #converting images to grayscale\n",
    "    img = img.mean(axis=2) # convert to grayscale\n",
    "    U, s, V = np.linalg.svd(img)\n",
    "    U = U[:, :n]\n",
    "    s = s[:n]\n",
    "    us = np.dot(U, np.diag(s))\n",
    "    return us\n",
    "#getting svd of all images\n",
    "'''\n",
    "Input : Directory of the images and number of features to be truncated\n",
    "Output : List of truncated US matrix\n",
    "'''\n",
    "def get_svd_images(img_dir, n):\n",
    "    img_files = os.listdir(img_dir)\n",
    "    img_files = [os.path.join(img_dir, f) for f in img_files]\n",
    "    #img_files = [plt.imread(f) for f in img_files]\n",
    "    # read images from file, resize them into 100x100, store in single array\n",
    "    img_files = [cv2.resize(plt.imread(f), (200, 200)) for f in img_files]\n",
    "    svd_images = [svd_truncate(img, n) for img in img_files]\n",
    "    return svd_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 200, 5)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train Images\n",
    "Input : Directory of the images and number of features to be truncated\n",
    "Output : Truncated US matrix of cats and dogs\n",
    "'''\n",
    "cat_images = get_svd_images(train_cats_dir, 5)\n",
    "cat_images = np.array(cat_images)\n",
    "dog_images = get_svd_images(train_dogs_dir, 5)\n",
    "dog_images = np.array(dog_images)\n",
    "#concatenating the images\n",
    "train_images = np.concatenate((cat_images, dog_images), axis=0)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "#creating labels for the train images\n",
    "train_labels = np.concatenate((np.zeros(len(cat_images)), np.ones(len(dog_images))), axis=0)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 200, 5)\n",
      "(50, 200, 5)\n",
      "(100, 200, 5)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Test Images\n",
    "Input : Directory of the images and number of features to be truncated\n",
    "Output : Truncated US matrix of cats and dogs\n",
    "'''\n",
    "test_cat_images = get_svd_images(test_cats_dir, 5)\n",
    "test_cat_images = np.array(test_cat_images)\n",
    "print(test_cat_images.shape)\n",
    "#test for dogs\n",
    "test_dog_images = get_svd_images(test_dogs_dir, 5)\n",
    "test_dog_images = np.array(test_dog_images)\n",
    "print(test_dog_images.shape)\n",
    "#concatenating the test images\n",
    "test_images = np.concatenate((test_cat_images, test_dog_images), axis=0)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n",
      "(100, 1000)\n"
     ]
    }
   ],
   "source": [
    "train_image_1d = np.array([img.flatten() for img in train_images])\n",
    "test_image_1d = np.array([img.flatten() for img in test_images])\n",
    "print(train_image_1d.shape)\n",
    "print(test_image_1d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "#creating labels for the test images\n",
    "test_labels = np.concatenate((np.zeros(len(test_cat_images)), np.ones(len(test_dog_images))), axis=0)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(train_image_1d, train_labels)\n",
    "y_pred = knn.predict(test_image_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43\n"
     ]
    }
   ],
   "source": [
    "kmenas= Kmeans(5)\n",
    "kmenas.fit(train_image_1d)\n",
    "y_pred = kmenas.predict(test_image_1d)\n",
    "print(accuracy_score(test_labels, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
