{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import turtle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_DIRECTORY  = \"/home/kalyan/DataSets/AadarshVroPaper/DataSet_Max_Clique/DomainToKingdom(Eukaryota)/\"\n",
    "CLASS = \"/Animals\"\n",
    "DIRECTORY = PARENT_DIRECTORY + CLASS\n",
    "FILES = os.listdir(DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2img():\n",
    "    def __init__(self, parent_dir, class_dir) -> None:\n",
    "        self.parent_dir = parent_dir\n",
    "        self.class_dir = class_dir\n",
    "        self.img_loc = \"/home/kalyan/gitrepo/IBS/New/\"\n",
    "        try:\n",
    "            os.makedirs(self.img_loc + self.class_dir)\n",
    "        except:\n",
    "            pass\n",
    "        self.dir = parent_dir + '/' + class_dir\n",
    "        seq_txt_files = os.listdir(self.dir)\n",
    "        file_iter = 1\n",
    "        for file in seq_txt_files:\n",
    "            sequence = self.get_Sequence(file)\n",
    "            x_plt, y_plt = self.seq_img(sequence)\n",
    "            self.save_plot_img(x_plt, y_plt, file_iter)\n",
    "            file_iter += 1\n",
    "        pass\n",
    "\n",
    "    def get_Sequence(self, seq_file):\n",
    "        data = open(self.dir + '/' + seq_file)\n",
    "        data = data.readlines()\n",
    "        seq = ''\n",
    "        for dna in data:\n",
    "            seq = seq + dna.split('\\n')[0]\n",
    "        return seq[:3000]\n",
    "\n",
    "    def seq_img(self, seq):\n",
    "        x = 1000\n",
    "        y = 1000\n",
    "        angle = 0\n",
    "        path = []\n",
    "        for i in seq[:3000]:\n",
    "            if (i == 'A'):\n",
    "                #path.append((x, y))\n",
    "                angle += np.pi/6\n",
    "                x += np.cos(angle)\n",
    "                y += np.sin(angle)\n",
    "                path.append((x, y))\n",
    "        \n",
    "            elif (i == 'T'):\n",
    "                #path.append((x, y))\n",
    "                angle += np.pi/4\n",
    "                x += np.cos(angle)\n",
    "                y += np.sin(angle)\n",
    "                path.append((x, y))\n",
    "        \n",
    "            elif (i == 'C'):\n",
    "                #path.append((x, y))\n",
    "                angle -= np.pi/2\n",
    "                x += np.cos(angle)\n",
    "                y += np.sin(angle)\n",
    "                path.append((x, y))\n",
    "        \n",
    "        \n",
    "            elif (i == 'G'):\n",
    "                #path.append((x, y))\n",
    "                angle -= np.pi\n",
    "                x += np.cos(angle)\n",
    "                y += np.sin(angle)\n",
    "                path.append((x, y))\n",
    "        x_plt = []\n",
    "        y_plt = []\n",
    "        for i in path:\n",
    "            x_plt.append(i[0])\n",
    "            y_plt.append(i[1])\n",
    "\n",
    "        return x_plt, y_plt\n",
    "\n",
    "    def save_plot_img(self, x_plt, y_plt, img_iter):\n",
    "        plt.figure(figsize=(5, 2.5))\n",
    "        plt.plot(x_plt, y_plt)\n",
    "        plt.savefig(self.img_loc + self.class_dir + '/' + self.class_dir + str (img_iter) + '.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = seq2img(PARENT_DIRECTORY, CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "#print number of folders in a given directory\n",
    "a = \"/home/kalyan/gitrepo/IBS/Sequence_Images\"\n",
    "print(len(os.listdir(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 15:35:40.483114: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-02 15:35:40.759107: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-02 15:35:41.895949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.0/lib64::/usr/local/tensorrt/lib/\n",
      "2023-02-02 15:35:41.896113: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.0/lib64::/usr/local/tensorrt/lib/\n",
      "2023-02-02 15:35:41.896126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_DIRECTORY = \"/home/kalyan/gitrepo/alma-mater/Sem3/Projects/IBS/\"\n",
    "CLASSES = os.listdir(PARENT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 607 files belonging to 3 classes.\n",
      "Using 456 files for training.\n",
      "Found 607 files belonging to 3 classes.\n",
      "Using 151 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 15:35:45.008653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-02 15:35:45.079313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-02 15:35:45.079579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-02 15:35:45.080142: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-02 15:35:45.080679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-02 15:35:45.080894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-02 15:35:45.081099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-02 15:35:45.791227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-02 15:35:45.791519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-02 15:35:45.791740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-02 15:35:45.791935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2617 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "training_data = tf.keras.preprocessing.image_dataset_from_directory(PARENT_DIRECTORY, labels='inferred', label_mode='categorical', seed=9,\n",
    "                                                                batch_size=8, image_size=[200, 100], shuffle=True,\n",
    "                                                                validation_split=0.25, subset='training', color_mode='grayscale')\n",
    "\n",
    "testing_data = tf.keras.preprocessing.image_dataset_from_directory(PARENT_DIRECTORY, labels='inferred', label_mode='categorical', seed=9,\n",
    "                                                                batch_size=8, image_size=[200, 100], shuffle=True,\n",
    "                                                                validation_split=0.25, subset='validation', color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 200, 100, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 3), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(200, 100, 1)),\n",
    "\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(5, 5), activation='relu'),\n",
    "\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 198, 98, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 99, 49, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 95, 45, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 47, 22, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 45, 20, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 10, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 11, 5, 16)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 880)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                28192     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,347\n",
      "Trainable params: 59,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build()\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model and loging to tensorboard\n",
    "import datetime\n",
    "\n",
    "\n",
    "log_dir = \"/home/kalyan/gitrepo/IBS/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 15:35:52.037658: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 4s 22ms/step - loss: 1.3093 - accuracy: 0.8596 - val_loss: 0.3716 - val_accuracy: 0.9205\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.4049 - accuracy: 0.8882 - val_loss: 0.2736 - val_accuracy: 0.9205\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3075 - accuracy: 0.9079 - val_loss: 0.4099 - val_accuracy: 0.9205\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3288 - accuracy: 0.9079 - val_loss: 0.3056 - val_accuracy: 0.9205\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3085 - accuracy: 0.9079 - val_loss: 0.2802 - val_accuracy: 0.9205\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.3354 - accuracy: 0.9101 - val_loss: 0.2890 - val_accuracy: 0.9205\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.3315 - accuracy: 0.9079 - val_loss: 0.2984 - val_accuracy: 0.9205\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.3277 - accuracy: 0.9079 - val_loss: 0.4536 - val_accuracy: 0.9205\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.3285 - accuracy: 0.9079 - val_loss: 0.2805 - val_accuracy: 0.9205\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.3230 - accuracy: 0.9079 - val_loss: 0.2777 - val_accuracy: 0.9205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2dcbb55960>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data, epochs=10, validation_data=testing_data, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "858efc061b545416e25caa8d4697e72d127b15a1bac3735708778cd5f37dd3d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
